* Get mean log loss metric for level 1 and level 2
* Get and look at feature importance
* Train models for labels other than toxic only on the subset of data that is labeled toxic
* Train models on additional data 
* Add their API as a level 1 model (https://github.com/conversationai/perspectiveapi/blob/master/api_reference.md - I already have access)
* Additional level 1 models (VW, XGB, LGB, NN, SVM)
* Additional level 2 models
* Additional feature engineering
* Data cleaning?
* Model based on a static blacklist (see https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/46035 / https://www.kaggle.com/c/detecting-insults-in-social-commentary/discussion/2744 / https://kaggle2.blob.core.windows.net/forum-message-attachments/4810/badwords.txt)
* Use other external data (in data folder / see https://www.kaggle.com/c/jigsaw-toxic-comment-classification-challenge/discussion/46035)
* Also use https://conversationai.github.io/wikidetox/testdata/tox-sorted/Wikipedia%20Toxicity%20Sorted%20%28Toxicity%405%5BAlpha%5D%29.html
* Tune model hyperparams
