* Get mean log loss metric for level 1 and level 2
* Get and look at feature importance
* Train models for labels other than toxic only on the subset of data that is labeled toxic
* Train models on additional data 
* Add their API as a level 1 model
* Additional level 1 models (VW, XGB, LGB, NN, SVM)
* Additional level 2 models
* Additional feature engineering
* Data cleaning?
* Model based on a static blacklist (make sure it is approved external data) (see https://www.kaggle.com/c/detecting-insults-in-social-commentary/discussion/2744)
